{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"lGxnD3UbdWmb","executionInfo":{"status":"ok","timestamp":1754078469644,"user_tz":-120,"elapsed":18290,"user":{"displayName":"Mattia Cappellino","userId":"05271634366428679167"}}},"outputs":[],"source":["# ── A. Imports & Reproducibility ────────────────────────────────────────────────\n","import os, copy\n","import csv                                                  # For result logging :contentReference[oaicite:0]{index=0}\n","import random                                               # For seeding :contentReference[oaicite:1]{index=1}\n","import numpy as np                                          # For numeric ops :contentReference[oaicite:2]{index=2}\n","import torch                                               # Core PyTorch :contentReference[oaicite:3]{index=3}\n","import torch.nn as nn                                       # Neural-net modules :contentReference[oaicite:4]{index=4}\n","import torch.nn.functional as F                             # Functional API :contentReference[oaicite:5]{index=5}\n","import torch.optim as optim                                 # Optimizers :contentReference[oaicite:6]{index=6}\n","from torch.optim.lr_scheduler import CosineAnnealingLR      # Scheduler :contentReference[oaicite:7]{index=7}\n","from torch.utils.data import DataLoader, random_split       # Data loaders & splits :contentReference[oaicite:8]{index=8}\n","import torchvision                                          # Datasets & transforms :contentReference[oaicite:9]{index=9}\n","import torchvision.transforms as T                          # Transforms :contentReference[oaicite:10]{index=10}\n","from torch.utils.tensorboard import SummaryWriter           # TensorBoard logging :contentReference[oaicite:11]{index=11}\n","import matplotlib.pyplot as plt                             # Plotting :contentReference[oaicite:12]{index=12}"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"39Q3SwyBdWnP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1754078469764,"user_tz":-120,"elapsed":132,"user":{"displayName":"Mattia Cappellino","userId":"05271634366428679167"}},"outputId":"98fab035-474a-4dae-ca0a-2345b3d2be4a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n"]}],"source":["# Seed everything for reproducibility\n","seed = 42\n","random.seed(seed)\n","np.random.seed(seed)\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed_all(seed)\n","\n","\n","# ── B. Device ───────────────────────────────────────────────────────────────────\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")                             # Confirm GPU vs CPU :contentReference[oaicite:13]{index=13}\n","\n","\n","\n","# ── C. Data Preparation ─────────────────────────────────────────────────────────\n","# Transforms\n","transform_train = T.Compose([\n","    T.RandomCrop(32, padding=4), T.RandomHorizontalFlip(),\n","    T.ToTensor(),\n","    T.Normalize((0.5071,0.4867,0.4408),(0.2675,0.2565,0.2761)),\n","])\n","transform_test = T.Compose([\n","    T.ToTensor(),\n","    T.Normalize((0.5071,0.4867,0.4408),(0.2675,0.2565,0.2761)),\n","])\n"]},{"cell_type":"code","source":["import glob, torch, os\n","\n","def latest_ckpt(dirpath, pattern=\"last_ckpt_round_*.pth\"):\n","    paths = glob.glob(os.path.join(dirpath, pattern))\n","    if not paths:\n","        return None\n","    paths.sort(key=lambda p: int(p.rsplit(\"_\", 1)[1].split(\".\")[0]))\n","    return paths[-1]\n","\n","\n","def load_checkpoint(model, optimizer, ckpt_dir, resume=True):\n","    if not resume:\n","        print(\"[Checkpoint] Starting training from scratch.\")\n","        return 1\n","    ckpt_path = latest_ckpt(ckpt_dir)\n","    if ckpt_path is None:\n","        print(\"[Checkpoint] No checkpoint found; training from scratch.\")\n","        return 1\n","    # Load checkpoint tensors onto CPU to preserve RNG state tensor\n","    ckpt = torch.load(ckpt_path, map_location='cpu')\n","    model.load_state_dict(ckpt['model_state'])\n","    optimizer.load_state_dict(ckpt['optimizer_state'])\n","    # Restore CPU RNG state\n","    rng_state = ckpt['rng_state']\n","    if rng_state.device.type != 'cpu':\n","        rng_state = rng_state.cpu()\n","    torch.set_rng_state(rng_state)\n","    print(f\"[Checkpoint] Resumed from round {ckpt['round']} (loaded {os.path.basename(ckpt_path)})\")\n","    return ckpt['round'] + 1\n","\n","\n","def save_checkpoint(model, optimizer, round_num, ckpt_dir, is_best=False):\n","    print(f\"[Checkpoint] Saving round {round_num}...\")\n","    state = {\n","        'round': round_num,\n","        'model_state': model.state_dict(),\n","        'optimizer_state': optimizer.state_dict(),\n","        'rng_state': torch.get_rng_state(),\n","    }\n","    fname = f\"{'best' if is_best else 'last'}_ckpt_round_{round_num}.pth\"\n","    torch.save(state, os.path.join(ckpt_dir, fname))\n","    if is_best:\n","        torch.save(model.state_dict(), os.path.join(ckpt_dir, 'best_model.pth'))\n","    print(f\"[Checkpoint] Done saving to {fname}\")\n","\n"],"metadata":{"id":"bF8TWhdImubH","executionInfo":{"status":"ok","timestamp":1754078469875,"user_tz":-120,"elapsed":110,"user":{"displayName":"Mattia Cappellino","userId":"05271634366428679167"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":17611,"status":"ok","timestamp":1754078487488,"user":{"displayName":"Mattia Cappellino","userId":"05271634366428679167"},"user_tz":-120},"id":"1KsmNAdjdWqH","colab":{"base_uri":"https://localhost:8080/"},"outputId":"57f6082f-3308-4ea0-ebbe-18f9f278bf3b"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 169M/169M [00:12<00:00, 13.5MB/s]\n"]}],"source":["# ── C. Data Preparation ─────────────────────────────────────────────────────────\n","# Transforms (as before)…\n","\n","# Download full CIFAR‑100 training set\n","full_train = torchvision.datasets.CIFAR100(\n","    root='./data', train=True, download=True, transform=transform_train\n",")\n","\n","# 1) Centralized validation split\n","val_size   = 5000\n","train_size = len(full_train) - val_size\n","train_dataset, val_dataset = random_split(\n","    full_train,\n","    [train_size, val_size],\n","    generator=torch.Generator().manual_seed(seed)\n",")\n","\n","# ── C.1 Build validation loader ───────────────────────────────\n","BS_VAL = 256\n","val_loader = DataLoader(\n","    val_dataset,\n","    batch_size=BS_VAL,\n","    shuffle=False,\n","    num_workers=2\n",")\n","\n","\n","# 2) IID sharding of the remaining train_dataset into K=100 clients\n","K = 100\n","base = train_size // K\n","sizes = [base] * (K - 1) + [train_size - base * (K - 1)]\n","shards = random_split(\n","    train_dataset,\n","    sizes,\n","    generator=torch.Generator().manual_seed(seed)\n","    )\n","\n","\n","# 3) Global test set (unchanged)\n","test_dataset = torchvision.datasets.CIFAR100(\n","    root='./data', train=False, download=True, transform=transform_test\n",")\n","\n","bs_test = 256\n","test_loader = DataLoader(\n","    test_dataset, batch_size=bs_test, shuffle=False, num_workers=2\n",")\n","\n","# 4) (Later) you can build per-client loaders:\n","# client_loaders = [\n","#     DataLoader(shards[i], batch_size=bs, shuffle=True, num_workers=2)\n","#     for i in range(K)\n","# ]\n"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"9zukJAc0dWq0","executionInfo":{"status":"ok","timestamp":1754078487504,"user_tz":-120,"elapsed":14,"user":{"displayName":"Mattia Cappellino","userId":"05271634366428679167"}}},"outputs":[],"source":["# ── D. Model Definition ─────────────────────────────────────────────────────────\n","class LELeNetCIFAR(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.conv1 = nn.Conv2d(3, 64, kernel_size=5, padding=2)\n","        self.pool1 = nn.MaxPool2d(2)\n","        self.conv2 = nn.Conv2d(64, 64, kernel_size=5, padding=2)\n","        self.pool2 = nn.MaxPool2d(2)\n","        self.fc1   = nn.Linear(64*8*8, 384)\n","        self.fc2   = nn.Linear(384, 192)\n","        self.fc3   = nn.Linear(192, 100)\n","    def forward(self, x):\n","        x = self.pool1(F.relu(self.conv1(x)))\n","        x = self.pool2(F.relu(self.conv2(x)))\n","        x = torch.flatten(x, 1)\n","        x = F.relu(self.fc1(x)); x = F.relu(self.fc2(x))\n","        return self.fc3(x)"]},{"cell_type":"code","source":["# ── E. Utilities: Train/Eval & Checkpointing ────────────────────────────────────\n","def train_one_epoch(model, optimizer, criterion, loader):\n","    model.train()\n","    running_loss = correct = total = 0\n","    for imgs, lbls in loader:\n","        imgs, lbls = imgs.to(device), lbls.to(device)\n","        optimizer.zero_grad()\n","        out = model(imgs)\n","        loss = criterion(out, lbls)\n","        loss.backward(); optimizer.step()\n","        running_loss += loss.item()*imgs.size(0)\n","        correct += out.argmax(1).eq(lbls).sum().item()\n","        total += lbls.size(0)\n","    return running_loss/total, correct/total\n","\n","def eval_model(model, criterion, loader):\n","    model.eval()\n","    running_loss = correct = total = 0\n","    with torch.no_grad():\n","        for imgs, lbls in loader:\n","            imgs, lbls = imgs.to(device), lbls.to(device)\n","            out = model(imgs); loss = criterion(out, lbls)\n","            running_loss += loss.item()*imgs.size(0)\n","            correct += out.argmax(1).eq(lbls).sum().item()\n","            total += lbls.size(0)\n","    return running_loss/total, correct/total\n","\n","\n","def sample_clients_dirichlet(K, m, gamma, rng=None):\n","    \"\"\"\n","    Sample m clients out of K with probabilities drawn from a Dirichlet(gamma) distribution.\n","    Returns:\n","      selected: list of client indices\n","      p:      numpy array of length K with the sampling probabilities\n","    \"\"\"\n","    rng = np.random.default_rng(seed)\n","    if gamma == 'uniform':\n","        p = np.ones(K) / K\n","        selected = rng.choice(K, size=m, replace=False)\n","    else:\n","        alpha = np.ones(K) * gamma\n","        p = rng.dirichlet(alpha)\n","        p = p / p.sum()                          # ensure sum=1\n","        selected = rng.choice(K, size=m, replace=False, p=p)\n","    return selected.tolist(), p\n","\n"],"metadata":{"id":"bnOGpNdtw-X0","executionInfo":{"status":"ok","timestamp":1754079040020,"user_tz":-120,"elapsed":5,"user":{"displayName":"Mattia Cappellino","userId":"05271634366428679167"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":616},"id":"QAGLQObvdWs7","outputId":"6d1ed3c1-c7cc-44ef-e651-e005cb227308","executionInfo":{"status":"error","timestamp":1754079427991,"user_tz":-120,"elapsed":373651,"user":{"displayName":"Mattia Cappellino","userId":"05271634366428679167"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","[Checkpoint] No checkpoint found; training from scratch.\n","[Training] Beginning training from round 1 to 2000.\n","Saving checkpoint 1 on Google Drive\n","[Checkpoint] Saving round 1...\n","[Checkpoint] Done saving to last_ckpt_round_1.pth\n","Round 1/2000 → Val Acc: 0.0102, Test Acc: 0.0098\n","Saving checkpoint 10 on Google Drive\n","[Checkpoint] Saving round 10...\n","[Checkpoint] Done saving to last_ckpt_round_10.pth\n","Round 10/2000 → Val Acc: 0.0560, Test Acc: 0.0550\n","Saving checkpoint 20 on Google Drive\n","[Checkpoint] Saving round 20...\n","[Checkpoint] Done saving to last_ckpt_round_20.pth\n","Round 20/2000 → Val Acc: 0.0964, Test Acc: 0.0982\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-372098648.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;31m# 4b) Test evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m     \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglobal_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;31m# 5) Checkpoint & logging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-4027412650.py\u001b[0m in \u001b[0;36meval_model\u001b[0;34m(model, criterion, loader)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlbls\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlbls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlbls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlbls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             if (\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1457\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1459\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1418\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1419\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1421\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1249\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1251\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["\n","# ── A. Mount Google Drive ─────────────────────────────────────────────────────\n","from google.colab import drive\n","import os\n","\n","drive.mount('/content/drive')\n","# Point to a folder inside your Drive for persistent checkpoints\n","CKPT_DIR = '/content/drive/MyDrive/fl_checkpoints'\n","os.makedirs(CKPT_DIR, exist_ok=True)\n","\n","\n","\n","\n","# Set this to True to resume from the last checkpoint; False to start from scratch\n","RESUME = True\n","\n","\n","\n","# ── A. FedAvg Hyperparameters ───────────────────────────────────────────────────\n","# Fixed FL parameters\n","K      = 100      # total clients\n","C      = 0.1      # fraction of clients sampled per round\n","J      = 4        # local epochs per client\n","ROUNDS = 2000  #2000     # total communication rounds\n","\n","# Optimizer hyperparameters (constant, no schedule)\n","LR     = 0.01     # fixed learning rate\n","WD     = 1e-4     # weight decay\n","BS     = 128      # per-client batch size\n","\n","#gamma value for dirichlet client selection\n","GAMMA = 10 #try later with 0.1 and 1.0 and 'uniform'\n","\n","# ── Instantiate TensorBoard writer ──────────────────────────────────────────────\n","from torch.utils.tensorboard import SummaryWriter\n","log_dir   = f\"./logs/FedAvg_lr{LR}_wd{WD}_bs{BS}\"\n","tb_writer = SummaryWriter(log_dir=log_dir)\n","\n","# ── B. CSV Logging Setup ────────────────────────────────────────────────────────\n","import csv, os\n","csv_path = './fedavg_results.csv'\n","\n","\n","\n","# ── B. CSV Logging Setup ────────────────────────────────────────────────────────\n","import csv, os\n","csv_path = './fedavg_results.csv'\n","if not os.path.exists(csv_path):\n","    with open(csv_path, 'w', newline='') as f:\n","        writer = csv.writer(f)\n","        writer.writerow([\n","            'round',\n","            'val_loss', 'val_acc',\n","            'test_loss', 'test_acc'\n","        ])\n","\n","# Before your FedAvg loop: Instantiate the global model, loss, and client loaders once\n","\n","# Instantiate model, optimizer, loss, and client loaders\n","global_model   = LELeNetCIFAR().to(device)\n","optimizer      = optim.SGD(global_model.parameters(), lr=LR, momentum=0.9, weight_decay=WD)\n","criterion      = nn.CrossEntropyLoss()\n","client_loaders = [\n","    DataLoader(shards[i], batch_size=BS, shuffle=True, num_workers=2)\n","    for i in range(K)\n","]\n","\n","\n","\n","\n","\n","# Load checkpoint (or start at 1)\n","start_round = load_checkpoint(global_model, optimizer, CKPT_DIR, resume=RESUME)\n","\n","\n","\n","\n","\n","\n","print(f\"[Training] Beginning training from round {start_round} to {ROUNDS}.\")\n","\n","# ── C. FedAvg Training Loop ─────────────────────────────────────────────────────\n","for rnd in range(start_round, ROUNDS + 1):\n","    # 1) Sample clients\n","    #print(f\"[Round {rnd}] Sampling {int(C*K)} clients...\")\n","    m = max(1, int(C * K))      # → 10 clients per round when K=100, C=0.1\n","    selected, p = sample_clients_dirichlet(K, m, gamma=GAMMA)\n","    #sampling_probs_history.append(p)\n","\n","    local_states, sizes = [], []\n","    for i in selected:\n","        # 2a) Copy global model\n","        client_model = copy.deepcopy(global_model)\n","        client_model.train()\n","        client_opt = optim.SGD(client_model.parameters(), lr=LR, momentum=0.9, weight_decay=WD)\n","\n","        # 2b) Local training for J epochs\n","        for _ in range(J):\n","            loss, acc = train_one_epoch(client_model, client_opt, criterion, client_loaders[i])\n","        local_states.append(client_model.state_dict())\n","        sizes.append(len(shards[i]))\n","\n","\n","\n","    # 3) Weighted aggregation\n","    total_size = sum(sizes)\n","    new_state = {}\n","    for k in global_model.state_dict():\n","        new_state[k] = sum((sizes[j] / total_size) * local_states[j][k] for j in range(len(sizes)))\n","    global_model.load_state_dict(new_state)\n","\n","    # 4) Global evaluation\n","    # 4a) Validation evaluation\n","    val_loss, val_acc = eval_model(global_model, criterion, val_loader)\n","\n","    # 4b) Test evaluation\n","    test_loss, test_acc = eval_model(global_model, criterion, test_loader)\n","\n","    # 5) Checkpoint & logging\n","    with open(csv_path, 'a', newline='') as f:\n","        csv.writer(f).writerow([rnd,\n","                                f\"{val_loss:.4f}\", f\"{val_acc:.4f}\",\n","                                f\"{test_loss:.4f}\", f\"{test_acc:.4f}\"])\n","\n","\n","    # 6) TensorBoard logging\n","    tb_writer.add_scalar('Accuracy/Validation', val_acc, rnd)\n","    tb_writer.add_scalar('Loss/Validation',    val_loss, rnd)\n","    tb_writer.add_scalar('Accuracy/Test',       test_acc, rnd)\n","    tb_writer.add_scalar('Loss/Test',           test_loss, rnd)\n","\n","\n","    if rnd % 10 == 0 or rnd == 1:\n","        #diocan sono 7 MB l uno, ne salvo solo qualcuno\n","        print(f\"Saving checkpoint {rnd} on Google Drive\")\n","        save_checkpoint(global_model, optimizer, rnd, CKPT_DIR, is_best=False)\n","\n","        print(f\"Round {rnd}/{ROUNDS} → \"\n","              f\"Val Acc: {val_acc:.4f}, Test Acc: {test_acc:.4f}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Qx5SLtcQggbL","executionInfo":{"status":"aborted","timestamp":1754078525541,"user_tz":-120,"elapsed":74819,"user":{"displayName":"Mattia Cappellino","userId":"05271634366428679167"}}},"outputs":[],"source":["# ── Configuration Summary & Utilities for FedAvg ──────────────────────────────\n","\n","import os, sys, platform, time\n","import torch\n","import numpy as np\n","import random\n","from torch.utils.tensorboard import SummaryWriter\n","\n","# 1) Define and instantiate your TensorBoard writer\n","log_dir = f\"./logs/FedAvg_lr{LR}_wd{WD}_bs{BS}\"\n","tb_writer = SummaryWriter(log_dir=log_dir)\n","\n","# 2) Summary utility\n","def summarize_run(cfg, client_loaders, test_loader, writer=None):\n","    \"\"\"\n","    Print and log summary for a FedAvg run.\n","    \"\"\"\n","    ts = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n","    print(f\"\\n========== FEDAVG RUN SUMMARY ({ts}) ==========\")\n","    # Hyperparameters\n","    for key in ['lr','weight_decay','batch_size','K','C','J','ROUNDS']:\n","        print(f\"    • {key}: {cfg[key]}\")\n","    # Data info\n","    num_clients  = len(client_loaders)\n","    shard_size   = len(client_loaders[0].dataset)\n","    test_samples = len(test_loader.dataset)\n","    print(f\"    • clients (K): {num_clients}, shard size: {shard_size}\")\n","    print(f\"    • test samples: {test_samples}, batch size: {cfg['batch_size']}\")\n","    # Log to TensorBoard\n","    if writer:\n","        for key in ['lr','weight_decay','batch_size','K','C','J','ROUNDS']:\n","            writer.add_text(f'RunInfo/{key}', str(cfg[key]), 0)\n","\n","# 3) Checkpoint utility\n","ckpt_dir = './checkpoints'\n","os.makedirs(ckpt_dir, exist_ok=True)\n","\n","\n","# ── Example Usage ────────────────────────────────────────────────────────────────\n","\n","cfg = {\n","    'lr':           LR,\n","    'weight_decay': WD,\n","    'batch_size':   BS,\n","    'K':            K,\n","    'C':            C,\n","    'J':            J,\n","    'ROUNDS':       ROUNDS\n","}\n","\n","# Print and log your FedAvg setup before starting training:\n","summarize_run(cfg, client_loaders, test_loader, tb_writer)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VMYuWSfTdWtt","executionInfo":{"status":"aborted","timestamp":1754078525565,"user_tz":-120,"elapsed":74839,"user":{"displayName":"Mattia Cappellino","userId":"05271634366428679167"}}},"outputs":[],"source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","# 1. Load the correct results file\n","csv_path = './fedavg_results.csv'    # update to your actual path\n","df = pd.read_csv(csv_path)\n","\n","# 2. Inspect first/last entries\n","print(\"First 5 rounds:\")\n","display(df.head())\n","print(\"Last 5 rounds:\")\n","display(df.tail())\n","\n","# 3. Plot Test Accuracy over Federated Rounds\n","plt.figure(figsize=(12, 6))\n","plt.plot(df['round'], df['test_acc'], label='Test Acc')\n","plt.xlabel('Federated Round')\n","plt.ylabel('Global Test Accuracy')\n","plt.title('FedAvg on CIFAR-100: Test Accuracy over Rounds')\n","plt.grid(True)\n","plt.legend()\n","plt.tight_layout()\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3rNf-hPZdWuf","executionInfo":{"status":"aborted","timestamp":1754078525603,"user_tz":-120,"elapsed":74873,"user":{"displayName":"Mattia Cappellino","userId":"05271634366428679167"}}},"outputs":[],"source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","# 1. Load FedAvg results\n","csv_path = './fedavg_results.csv'\n","df = pd.read_csv(csv_path)\n","\n","# 2. Quick peek at the first/last few entries\n","print(\"First rounds:\")\n","display(df.head(5))\n","print(\"Last rounds:\")\n","display(df.tail(5))\n","\n","# 3. Plot Test Accuracy over Federated Rounds\n","plt.figure(figsize=(12, 6))\n","plt.plot(df['round'], df['test_acc'])\n","plt.xlabel('Federated Round')\n","plt.ylabel('Global Test Accuracy')\n","plt.title('FedAvg on CIFAR-100: Test Accuracy vs. Communication Round')\n","plt.grid(True)\n","plt.tight_layout()\n","plt.show()\n","\n","# 4. (Optional) Smooth curve with rolling average\n","df['smoothed_acc'] = df['test_acc'].rolling(window=50, min_periods=1).mean()\n","plt.figure(figsize=(12, 6))\n","plt.plot(df['round'], df['test_acc'], alpha=0.3, label='Raw')\n","plt.plot(df['round'], df['smoothed_acc'], label='50‐round MA')\n","plt.xlabel('Federated Round')\n","plt.ylabel('Global Test Accuracy')\n","plt.title('Smoothed FedAvg Accuracy Curve')\n","plt.legend()\n","plt.tight_layout()\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XZm-lbwPdWvT","executionInfo":{"status":"aborted","timestamp":1754078525605,"user_tz":-120,"elapsed":74874,"user":{"displayName":"Mattia Cappellino","userId":"05271634366428679167"}}},"outputs":[],"source":[]},{"cell_type":"code","source":["#ATTENZIONE!!!!\n","#OCCHIO A RUNNAREEEE\n","\n","\n","\n","#utility function that deletes all checkpoints from the checkpoint folder\n","\n","def clear_checkpoints(ckpt_dir):\n","    \"\"\"\n","    Remove all checkpoint files in the specified directory.\n","    \"\"\"\n","    removed = 0\n","    for fname in os.listdir(ckpt_dir):\n","        path = os.path.join(ckpt_dir, fname)\n","        if os.path.isfile(path):\n","            os.remove(path)\n","            removed += 1\n","    print(f\"[Checkpoint] Cleared {removed} files from {ckpt_dir}\")\n","\n","\n","clear_checkpoints(CKPT_DIR)\n"],"metadata":{"id":"00NdM_dr6vim","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1754079046131,"user_tz":-120,"elapsed":15,"user":{"displayName":"Mattia Cappellino","userId":"05271634366428679167"}},"outputId":"b634a6e4-d528-483b-ed73-e8ae96365178"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["[Checkpoint] Cleared 3 files from /content/drive/MyDrive/fl_checkpoints\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Owzk--gFdWwB","executionInfo":{"status":"aborted","timestamp":1754078525610,"user_tz":-120,"elapsed":74878,"user":{"displayName":"Mattia Cappellino","userId":"05271634366428679167"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q5IgnGhEdWw1","executionInfo":{"status":"aborted","timestamp":1754078525612,"user_tz":-120,"elapsed":74880,"user":{"displayName":"Mattia Cappellino","userId":"05271634366428679167"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E1O3ub6UdWxr","executionInfo":{"status":"aborted","timestamp":1754078525623,"user_tz":-120,"elapsed":74890,"user":{"displayName":"Mattia Cappellino","userId":"05271634366428679167"}}},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"1TE0jsvf4PTX7tN0Ngz_0NZfm8NoGgDgJ","timestamp":1753224018851},{"file_id":"1KYtrSgZWEprGxEteMTSH-NNBpr56IO0Y","timestamp":1753205697977}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}