{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"lGxnD3UbdWmb"},"outputs":[],"source":["# ── A. Imports & Reproducibility ────────────────────────────────────────────────\n","import os\n","import csv                                                  # For result logging :contentReference[oaicite:0]{index=0}\n","import random                                               # For seeding :contentReference[oaicite:1]{index=1}\n","import numpy as np                                          # For numeric ops :contentReference[oaicite:2]{index=2}\n","import torch                                               # Core PyTorch :contentReference[oaicite:3]{index=3}\n","import torch.nn as nn                                       # Neural-net modules :contentReference[oaicite:4]{index=4}\n","import torch.nn.functional as F                             # Functional API :contentReference[oaicite:5]{index=5}\n","import torch.optim as optim                                 # Optimizers :contentReference[oaicite:6]{index=6}\n","from torch.optim.lr_scheduler import CosineAnnealingLR      # Scheduler :contentReference[oaicite:7]{index=7}\n","from torch.utils.data import DataLoader, random_split       # Data loaders & splits :contentReference[oaicite:8]{index=8}\n","import torchvision                                          # Datasets & transforms :contentReference[oaicite:9]{index=9}\n","import torchvision.transforms as T                          # Transforms :contentReference[oaicite:10]{index=10}\n","from torch.utils.tensorboard import SummaryWriter           # TensorBoard logging :contentReference[oaicite:11]{index=11}\n","import matplotlib.pyplot as plt                             # Plotting :contentReference[oaicite:12]{index=12}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"39Q3SwyBdWnP"},"outputs":[],"source":["# Seed everything for reproducibility\n","seed = 42\n","random.seed(seed)\n","np.random.seed(seed)\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed_all(seed)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1746450506102,"user":{"displayName":"Mattia Cappellino","userId":"05271634366428679167"},"user_tz":-120},"id":"r0PBwz2GdWoD","outputId":"e7c49bfd-f989-4ada-fc33-32a24f86bf1d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using device: cpu\n"]}],"source":["# ── B. Device ───────────────────────────────────────────────────────────────────\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")                             # Confirm GPU vs CPU :contentReference[oaicite:13]{index=13}\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hocKqvhTdWpL"},"outputs":[],"source":["# ── C. Data Preparation ─────────────────────────────────────────────────────────\n","# Transforms\n","transform_train = T.Compose([\n","    T.RandomCrop(32, padding=4), T.RandomHorizontalFlip(),\n","    T.ToTensor(),\n","    T.Normalize((0.5071,0.4867,0.4408),(0.2675,0.2565,0.2761)),\n","])\n","transform_test = T.Compose([\n","    T.ToTensor(),\n","    T.Normalize((0.5071,0.4867,0.4408),(0.2675,0.2565,0.2761)),\n","])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6010,"status":"ok","timestamp":1746450512115,"user":{"displayName":"Mattia Cappellino","userId":"05271634366428679167"},"user_tz":-120},"id":"1KsmNAdjdWqH","outputId":"6c3bd418-5e4e-4961-ce02-87eafebe7687"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 169M/169M [00:01<00:00, 90.8MB/s]\n"]}],"source":["# Download & train/val/test split\n","dataset_full = torchvision.datasets.CIFAR100(\n","    root='./data', train=True, download=True, transform=transform_train)\n","val_size = 5000\n","train_size = len(dataset_full) - val_size\n","train_dataset, val_dataset = random_split(\n","    dataset_full, [train_size, val_size],\n","    generator=torch.Generator().manual_seed(seed))\n","test_dataset = torchvision.datasets.CIFAR100(\n","    root='./data', train=False, download=True, transform=transform_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9zukJAc0dWq0"},"outputs":[],"source":["# ── D. Model Definition ─────────────────────────────────────────────────────────\n","class LELeNetCIFAR(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.conv1 = nn.Conv2d(3, 64, kernel_size=5, padding=2)\n","        self.pool1 = nn.MaxPool2d(2)\n","        self.conv2 = nn.Conv2d(64, 64, kernel_size=5, padding=2)\n","        self.pool2 = nn.MaxPool2d(2)\n","        self.fc1   = nn.Linear(64*8*8, 384)\n","        self.fc2   = nn.Linear(384, 192)\n","        self.fc3   = nn.Linear(192, 100)\n","    def forward(self, x):\n","        x = self.pool1(F.relu(self.conv1(x)))\n","        x = self.pool2(F.relu(self.conv2(x)))\n","        x = torch.flatten(x, 1)\n","        x = F.relu(self.fc1(x)); x = F.relu(self.fc2(x))\n","        return self.fc3(x)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0ambCIcmdWrf"},"outputs":[],"source":["# ── E. Utilities: Train/Eval & Checkpointing ────────────────────────────────────\n","def train_one_epoch(model, optimizer, criterion, loader):\n","    model.train()\n","    running_loss = correct = total = 0\n","    for imgs, lbls in loader:\n","        imgs, lbls = imgs.to(device), lbls.to(device)\n","        optimizer.zero_grad()\n","        out = model(imgs)\n","        loss = criterion(out, lbls)\n","        loss.backward(); optimizer.step()\n","        running_loss += loss.item()*imgs.size(0)\n","        correct += out.argmax(1).eq(lbls).sum().item()\n","        total += lbls.size(0)\n","    return running_loss/total, correct/total\n","\n","def eval_model(model, criterion, loader):\n","    model.eval()\n","    running_loss = correct = total = 0\n","    with torch.no_grad():\n","        for imgs, lbls in loader:\n","            imgs, lbls = imgs.to(device), lbls.to(device)\n","            out = model(imgs); loss = criterion(out, lbls)\n","            running_loss += loss.item()*imgs.size(0)\n","            correct += out.argmax(1).eq(lbls).sum().item()\n","            total += lbls.size(0)\n","    return running_loss/total, correct/total"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ELDe-m-idWsO"},"outputs":[],"source":["# Checkpoint saves model + optimizer + scheduler + RNG\n","ckpt_dir = './checkpoints'\n","os.makedirs(ckpt_dir, exist_ok=True)\n","def save_checkpoint(model, optimizer, scheduler, epoch, is_best=False):\n","    fname = f\"{'best' if is_best else 'last'}_ckpt_epoch_{epoch}.pth\"\n","    torch.save({\n","        'epoch': epoch,\n","        'model_state': model.state_dict(),\n","        'optim_state': optimizer.state_dict(),\n","        'sched_state': scheduler.state_dict(),\n","        'rng_state': torch.get_rng_state(),\n","    }, os.path.join(ckpt_dir, fname))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"QAGLQObvdWs7","outputId":"ff8068e4-9922-48ff-eafa-4c7be80dab60"},"outputs":[{"name":"stdout","output_type":"stream","text":["Running config: lr=0.1, wd=0.0001, bs=128, epochs=100\n","  Epoch 1/100  train_acc=0.0623  val_acc=0.0950\n","  Epoch 2/100  train_acc=0.1017  val_acc=0.1318\n","  Epoch 3/100  train_acc=0.1217  val_acc=0.1360\n","  Epoch 4/100  train_acc=0.1371  val_acc=0.1506\n","  Epoch 5/100  train_acc=0.1470  val_acc=0.1336\n","  Epoch 6/100  train_acc=0.1574  val_acc=0.1580\n","  Epoch 7/100  train_acc=0.1665  val_acc=0.1746\n","  Epoch 8/100  train_acc=0.1687  val_acc=0.1504\n","  Epoch 9/100  train_acc=0.1734  val_acc=0.1584\n","  Epoch 10/100  train_acc=0.1782  val_acc=0.1836\n","  Epoch 11/100  train_acc=0.1884  val_acc=0.1862\n","  Epoch 12/100  train_acc=0.1890  val_acc=0.1930\n","  Epoch 13/100  train_acc=0.1900  val_acc=0.1904\n","  Epoch 14/100  train_acc=0.1966  val_acc=0.1952\n","  Epoch 15/100  train_acc=0.1939  val_acc=0.1882\n","  Epoch 16/100  train_acc=0.2024  val_acc=0.1790\n","  Epoch 17/100  train_acc=0.2020  val_acc=0.1990\n","  Epoch 18/100  train_acc=0.2056  val_acc=0.2122\n","  Epoch 19/100  train_acc=0.2117  val_acc=0.2072\n","  Epoch 20/100  train_acc=0.2184  val_acc=0.2070\n","  Epoch 21/100  train_acc=0.2174  val_acc=0.2034\n","  Epoch 22/100  train_acc=0.2252  val_acc=0.2096\n","  Epoch 23/100  train_acc=0.2260  val_acc=0.2226\n","  Epoch 24/100  train_acc=0.2293  val_acc=0.2318\n","  Epoch 25/100  train_acc=0.2323  val_acc=0.2448\n","  Epoch 26/100  train_acc=0.2390  val_acc=0.2346\n","  Epoch 27/100  train_acc=0.2428  val_acc=0.2224\n","  Epoch 28/100  train_acc=0.2506  val_acc=0.2450\n","  Epoch 29/100  train_acc=0.2516  val_acc=0.2466\n","  Epoch 30/100  train_acc=0.2562  val_acc=0.2416\n","  Epoch 31/100  train_acc=0.2608  val_acc=0.2508\n","  Epoch 32/100  train_acc=0.2673  val_acc=0.2592\n","  Epoch 33/100  train_acc=0.2722  val_acc=0.2602\n","  Epoch 34/100  train_acc=0.2794  val_acc=0.2708\n","  Epoch 35/100  train_acc=0.2848  val_acc=0.2706\n","  Epoch 36/100  train_acc=0.2922  val_acc=0.2686\n","  Epoch 37/100  train_acc=0.2963  val_acc=0.2820\n","  Epoch 38/100  train_acc=0.2995  val_acc=0.2834\n","  Epoch 39/100  train_acc=0.3054  val_acc=0.2794\n","  Epoch 40/100  train_acc=0.3134  val_acc=0.2884\n","  Epoch 41/100  train_acc=0.3175  val_acc=0.3052\n","  Epoch 42/100  train_acc=0.3276  val_acc=0.2924\n","  Epoch 43/100  train_acc=0.3321  val_acc=0.3024\n","  Epoch 44/100  train_acc=0.3375  val_acc=0.3122\n","  Epoch 45/100  train_acc=0.3454  val_acc=0.3190\n","  Epoch 46/100  train_acc=0.3548  val_acc=0.3222\n","  Epoch 47/100  train_acc=0.3620  val_acc=0.3184\n","  Epoch 48/100  train_acc=0.3631  val_acc=0.3286\n","  Epoch 49/100  train_acc=0.3753  val_acc=0.3446\n","  Epoch 50/100  train_acc=0.3816  val_acc=0.3216\n","  Epoch 51/100  train_acc=0.3905  val_acc=0.3456\n","  Epoch 52/100  train_acc=0.3979  val_acc=0.3578\n","  Epoch 53/100  train_acc=0.4023  val_acc=0.3566\n","  Epoch 54/100  train_acc=0.4134  val_acc=0.3502\n","  Epoch 55/100  train_acc=0.4198  val_acc=0.3696\n","  Epoch 56/100  train_acc=0.4326  val_acc=0.3630\n","  Epoch 57/100  train_acc=0.4371  val_acc=0.3632\n","  Epoch 58/100  train_acc=0.4470  val_acc=0.3784\n","  Epoch 59/100  train_acc=0.4504  val_acc=0.3854\n","  Epoch 60/100  train_acc=0.4638  val_acc=0.3890\n","  Epoch 61/100  train_acc=0.4697  val_acc=0.3854\n","  Epoch 62/100  train_acc=0.4756  val_acc=0.3988\n","  Epoch 63/100  train_acc=0.4860  val_acc=0.3996\n","  Epoch 64/100  train_acc=0.4951  val_acc=0.4078\n","  Epoch 65/100  train_acc=0.5045  val_acc=0.4170\n","  Epoch 66/100  train_acc=0.5138  val_acc=0.4072\n","  Epoch 67/100  train_acc=0.5208  val_acc=0.4108\n","  Epoch 68/100  train_acc=0.5307  val_acc=0.4216\n","  Epoch 69/100  train_acc=0.5391  val_acc=0.4138\n","  Epoch 70/100  train_acc=0.5402  val_acc=0.4262\n","  Epoch 71/100  train_acc=0.5578  val_acc=0.4238\n","  Epoch 72/100  train_acc=0.5595  val_acc=0.4306\n","  Epoch 73/100  train_acc=0.5710  val_acc=0.4392\n","  Epoch 74/100  train_acc=0.5795  val_acc=0.4380\n","  Epoch 75/100  train_acc=0.5898  val_acc=0.4428\n","  Epoch 76/100  train_acc=0.5971  val_acc=0.4340\n","  Epoch 77/100  train_acc=0.6049  val_acc=0.4484\n","  Epoch 78/100  train_acc=0.6090  val_acc=0.4456\n","  Epoch 79/100  train_acc=0.6203  val_acc=0.4494\n","  Epoch 80/100  train_acc=0.6274  val_acc=0.4548\n","  Epoch 81/100  train_acc=0.6356  val_acc=0.4538\n","  Epoch 82/100  train_acc=0.6415  val_acc=0.4610\n","  Epoch 83/100  train_acc=0.6494  val_acc=0.4560\n","  Epoch 84/100  train_acc=0.6556  val_acc=0.4572\n","  Epoch 85/100  train_acc=0.6640  val_acc=0.4678\n","  Epoch 86/100  train_acc=0.6663  val_acc=0.4694\n","  Epoch 87/100  train_acc=0.6765  val_acc=0.4656\n","  Epoch 88/100  train_acc=0.6772  val_acc=0.4656\n","  Epoch 89/100  train_acc=0.6825  val_acc=0.4666\n","  Epoch 90/100  train_acc=0.6899  val_acc=0.4672\n","  Epoch 91/100  train_acc=0.6920  val_acc=0.4748\n","  Epoch 92/100  train_acc=0.6963  val_acc=0.4676\n","  Epoch 93/100  train_acc=0.6959  val_acc=0.4666\n","  Epoch 94/100  train_acc=0.6995  val_acc=0.4838\n","  Epoch 95/100  train_acc=0.7058  val_acc=0.4868\n"]}],"source":["# ── A. Hyperparameter Grid ─────────────────────────────────────────────────────\n","param_grid = [\n","    {'lr': 0.1, 'weight_decay': 1e-4, 'batch_size': 128, 'epochs': 100},\n","    # … add more combinations as needed …\n","]\n","\n","\n","\n","\n","\n","#all config to test\n","#testing all with 128 and 100 for last 2 values\n","\n","#tested lr = 0.001 and weight decay = 1e-5\n","\"\"\"# ── Define the values you want to test ────────────────────────────────────────────\n","learning_rates   = [0.001, 0.01, 0.1]        # typical LR grid for CIFAR-100 :contentReference[oaicite:0]{index=0}\n","weight_decays    = [1e-5, 1e-4, 1e-3]        # common L2 regs :contentReference[oaicite:1]{index=1}\n","batch_sizes      = [32, 64, 128]             # fits 6 GB VRAM on Colab GPUs :contentReference[oaicite:2]{index=2}\n","epoch_counts     = [50, 100]                 # short vs full training\"\"\"\n","\n","\n","\n","\n","# Prepare CSV logging\n","csv_path = './results_grid.csv'\n","if not os.path.exists(csv_path):\n","    with open(csv_path, 'w', newline='') as f:\n","        writer = csv.writer(f)\n","        writer.writerow([\n","            'lr', 'weight_decay', 'batch_size', 'epochs',\n","            'best_val_acc', 'test_acc'\n","        ])\n","\n","# ── B. Loop Over Configurations ────────────────────────────────────────────────\n","for cfg in param_grid:\n","    lr, wd, bs, epochs = cfg['lr'], cfg['weight_decay'], cfg['batch_size'], cfg['epochs']\n","    print(f\"Running config: lr={lr}, wd={wd}, bs={bs}, epochs={epochs}\")\n","\n","    # Re-create DataLoaders per bs\n","    train_loader = DataLoader(train_dataset, batch_size=bs, shuffle=True, num_workers=2)\n","    val_loader   = DataLoader(val_dataset,   batch_size=bs, shuffle=False, num_workers=2)\n","    test_loader  = DataLoader(test_dataset,  batch_size=bs, shuffle=False, num_workers=2)\n","\n","    # Instantiate fresh model, optimizer, scheduler, writer\n","    model     = LELeNetCIFAR().to(device)\n","    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=wd)\n","    scheduler = CosineAnnealingLR(optimizer, T_max=epochs)\n","    criterion = nn.CrossEntropyLoss()\n","    writer    = SummaryWriter(log_dir=f'./logs/lr{lr}_wd{wd}_bs{bs}_ep{epochs}')\n","\n","    best_val_acc = 0.0\n","    for epoch in range(1, epochs+1):\n","        train_loss, train_acc = train_one_epoch(model, optimizer, criterion, train_loader)\n","        val_loss,   val_acc   = eval_model(model, criterion, val_loader)\n","        scheduler.step()\n","\n","        # Log to TensorBoard\n","        writer.add_scalars('Loss', {'train': train_loss, 'val': val_loss}, epoch)\n","        writer.add_scalars('Acc',  {'train': train_acc,  'val': val_acc},   epoch)\n","\n","        # Save checkpoints\n","        save_checkpoint(model, optimizer, scheduler, epoch, is_best=(val_acc>best_val_acc))\n","        if val_acc > best_val_acc:\n","            best_val_acc = val_acc\n","\n","        print(f\"  Epoch {epoch}/{epochs}  train_acc={train_acc:.4f}  val_acc={val_acc:.4f}\")\n","\n","    # Final Test Evaluation\n","    test_loss, test_acc = eval_model(model, criterion, test_loader)\n","    print(f\"Config {cfg} → best_val_acc={best_val_acc:.4f}, test_acc={test_acc:.4f}\")\n","\n","    # Append results to CSV\n","    with open(csv_path, 'a', newline='') as f:\n","        writer = csv.writer(f)\n","        writer.writerow([lr, wd, bs, epochs, best_val_acc, test_acc])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Qx5SLtcQggbL"},"outputs":[],"source":["# ── Configuration Summary Cell ──────────────────────────────────────────────────\n","import torch, torchvision, sys, platform, time, os\n","import numpy as np\n","import random\n","from torch.utils.tensorboard import SummaryWriter\n","\n","def summarize_run(cfg, train_loader, val_loader, test_loader, writer=None):\n","    \"\"\"\n","    Print and log a full summary of the current run configuration and environment.\n","\n","    Args:\n","        cfg (dict): Hyperparameter dict with 'lr', 'weight_decay', 'batch_size', 'epochs', etc.\n","        train_loader, val_loader, test_loader: DataLoaders for computing dataset sizes.\n","        writer (SummaryWriter, optional): if provided, logs summary to TensorBoard under 'RunInfo'.\n","    \"\"\"\n","    # 1. Timestamp\n","    ts = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n","\n","    # 2. Environment\n","    env_info = {\n","        'python_version': sys.version.split()[0],\n","        'pytorch_version': torch.__version__,\n","        'torchvision_version': torchvision.__version__,\n","        'cuda_available': torch.cuda.is_available(),\n","        'cuda_device': torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU only',\n","        'device_count': torch.cuda.device_count() if torch.cuda.is_available() else 0,\n","        'platform': platform.platform(),\n","        'cwd': os.getcwd(),\n","    }\n","\n","    # 3. Data sizes\n","    data_info = {\n","        'train_samples': len(train_loader.dataset),\n","        'val_samples': len(val_loader.dataset),\n","        'test_samples': len(test_loader.dataset),\n","        'batch_size': cfg.get('batch_size'),\n","        'num_batches_train': len(train_loader),\n","        'num_batches_val': len(val_loader),\n","        'num_batches_test': len(test_loader),\n","    }\n","\n","    # 4. Seed & Hyperparams\n","    seed_info = {\n","        'seed': cfg.get('seed', 'not set'),\n","    }\n","    hyperparams = {k: v for k, v in cfg.items() if k not in seed_info}\n","\n","    # 5. Print Summary\n","    print(f\"{'='*20} RUN SUMMARY ({ts}) {'='*20}\\n\")\n","    print(\"➜ Environment:\")\n","    for k, v in env_info.items():\n","        print(f\"    • {k}: {v}\")\n","    print(\"\\n➜ Data:\")\n","    for k, v in data_info.items():\n","        print(f\"    • {k}: {v}\")\n","    print(\"\\n➜ Seed:\")\n","    for k, v in seed_info.items():\n","        print(f\"    • {k}: {v}\")\n","    print(\"\\n➜ Hyperparameters:\")\n","    for k, v in hyperparams.items():\n","        print(f\"    • {k}: {v}\")\n","    print(f\"\\n{'='*60}\\n\")\n","\n","    # 6. Optional TensorBoard Logging\n","    if writer is not None:\n","        for k, v in {**env_info, **data_info, **seed_info, **hyperparams}.items():\n","            # Non-numeric values will be logged as text under a scalar tag\n","            try:\n","                writer.add_text('RunInfo/' + k, str(v), 0)\n","            except Exception:\n","                pass\n","\n","# ── Example Usage ────────────────────────────────────────────────────────────────\n","# After defining `cfg`, DataLoaders, and `writer` in your Run Cell, just call:\n","summarize_run(cfg, train_loader, val_loader, test_loader, writer)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VMYuWSfTdWtt"},"outputs":[],"source":["import pandas as pd\n","df = pd.read_csv('./results_grid.csv')\n","display(df.sort_values('test_acc', ascending=False))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3rNf-hPZdWuf"},"outputs":[],"source":["# ── Final Analysis & Plotting ────────────────────────────────────────────────────\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","# 1. Load results\n","csv_path = './results_grid.csv'\n","df = pd.read_csv(csv_path)\n","\n","# 2. Display top 5 configs by test accuracy\n","top5 = df.sort_values('test_acc', ascending=False).head(5)\n","print(\"Top 5 hyperparameter configurations:\")\n","display(top5)\n","\n","# 3. Bar plot of test accuracy for each config\n","plt.figure(figsize=(10, 6))\n","plt.bar(\n","    x=range(len(df)),\n","    height=df['test_acc'],\n","    tick_label=[f\"lr={lr}\\nwd={wd}\\nbs={bs}\\nep={ep}\"\n","                for lr, wd, bs, ep in zip(df['lr'], df['weight_decay'], df['batch_size'], df['epochs'])]\n",")\n","plt.xticks(rotation=45, ha='right')\n","plt.ylabel('Test Accuracy')\n","plt.title('Grid Search Results: Test Accuracy by Hyperparameter Configuration')\n","plt.tight_layout()\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XZm-lbwPdWvT"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Owzk--gFdWwB"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q5IgnGhEdWw1"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E1O3ub6UdWxr"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"authorship_tag":"ABX9TyMO88ACkR5/uTJX6n18OJVi"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}