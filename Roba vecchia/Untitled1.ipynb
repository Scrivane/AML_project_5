{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4036,"status":"ok","timestamp":1746029680534,"user":{"displayName":"Mattia Cappellino","userId":"05271634366428679167"},"user_tz":-120},"id":"UaF9nPPdbi1q","outputId":"7fd7d81a-599d-434f-b2f8-b9c218d474d6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (4.3.0)\n","Requirement already satisfied: alembic\u003e=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (1.15.2)\n","Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna) (6.9.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n","Requirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n","Requirement already satisfied: sqlalchemy\u003e=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.40)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n","Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic\u003e=1.5.0-\u003eoptuna) (1.1.3)\n","Requirement already satisfied: typing-extensions\u003e=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic\u003e=1.5.0-\u003eoptuna) (4.13.2)\n","Requirement already satisfied: greenlet\u003e=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy\u003e=1.4.2-\u003eoptuna) (3.2.1)\n"]}],"source":["# Install Optuna\n","!pip install optuna\n","\n","import optuna                                                  # Optuna framework :contentReference[oaicite:10]{index=10}\n","from torch.optim.lr_scheduler import CosineAnnealingLR\n","from torch.utils.data import DataLoader, random_split\n","import torchvision.transforms as T\n","import torchvision\n","import torch, torch.nn as nn, torch.nn.functional as F, torch.optim as optim\n","import random, numpy as np, os"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":70},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1746029686285,"user":{"displayName":"Mattia Cappellino","userId":"05271634366428679167"},"user_tz":-120},"id":"pvElJgfVb-Js","outputId":"14191d15-9e71-4eea-b3f8-aad8a5cdc1d9"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'seed = 42\\ntorch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\\nnp.random.seed(seed); random.seed(seed)\\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")'"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["# ── Reuse Your Existing Setup\n","# (Sections 1-4: reproducibility, device, data prep, model definition)\n","\"\"\"seed = 42\n","torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n","np.random.seed(seed); random.seed(seed)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\"\"\""]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1746029688359,"user":{"displayName":"Mattia Cappellino","userId":"05271634366428679167"},"user_tz":-120},"id":"frKwNHPob-Kj"},"outputs":[],"source":["\n","# ── 1. Reproducibility ───────────────────────────────────────────────────────────\n","seed = 42\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed_all(seed)\n","np.random.seed(seed)\n","random.seed(seed)"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1746029689285,"user":{"displayName":"Mattia Cappellino","userId":"05271634366428679167"},"user_tz":-120},"id":"mRGRvO-bb-LY","outputId":"496e41f0-f8de-438a-c5c8-616e4faba2d1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using device: cpu\n"]}],"source":["# ── 2. Device ───────────────────────────────────────────────────────────────────\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Using device:\", device)"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1746029690207,"user":{"displayName":"Mattia Cappellino","userId":"05271634366428679167"},"user_tz":-120},"id":"Mesek5Gwb-NM"},"outputs":[],"source":["# ── 3. Data Preparation ─────────────────────────────────────────────────────────\n","# Transforms\n","transform_train = T.Compose([\n","    T.RandomCrop(32, padding=4),\n","    T.RandomHorizontalFlip(),\n","    T.ToTensor(),\n","    T.Normalize((0.5071, 0.4867, 0.4408),\n","                (0.2675, 0.2565, 0.2761)),\n","])\n","transform_test = T.Compose([\n","    T.ToTensor(),\n","    T.Normalize((0.5071, 0.4867, 0.4408),\n","                (0.2675, 0.2565, 0.2761)),\n","])"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15580,"status":"ok","timestamp":1746029706976,"user":{"displayName":"Mattia Cappellino","userId":"05271634366428679167"},"user_tz":-120},"id":"kLnW20BYb-OC","outputId":"853226d0-eb75-4577-a4a7-7b75fdd6b5c9"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 169M/169M [00:07\u003c00:00, 24.1MB/s]\n"]}],"source":["# Download \u0026 split\n","dataset_full = torchvision.datasets.CIFAR100(\n","    root='./data', train=True, download=True, transform=transform_train)\n","val_size = 5000\n","train_size = len(dataset_full) - val_size\n","train_dataset, val_dataset = random_split(\n","    dataset_full, [train_size, val_size],\n","    generator=torch.Generator().manual_seed(seed))\n","test_dataset = torchvision.datasets.CIFAR100(\n","    root='./data', train=False, download=True, transform=transform_test)"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1746029706992,"user":{"displayName":"Mattia Cappellino","userId":"05271634366428679167"},"user_tz":-120},"id":"1b9LoBRBb-O3"},"outputs":[],"source":["# DataLoaders (batch_size=64 per paper)\n","batch_size = 64\n","train_loader = DataLoader(\n","    train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n","val_loader = DataLoader(\n","    val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n","test_loader = DataLoader(\n","    test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1746029706994,"user":{"displayName":"Mattia Cappellino","userId":"05271634366428679167"},"user_tz":-120},"id":"ssDC5LX9b-ZM"},"outputs":[],"source":["# Model from [11]\n","class LELeNetCIFAR(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.conv1 = nn.Conv2d(3,64,kernel_size=5,padding=2)\n","        self.pool1 = nn.MaxPool2d(2)\n","        self.conv2 = nn.Conv2d(64,64,kernel_size=5,padding=2)\n","        self.pool2 = nn.MaxPool2d(2)\n","        self.fc1   = nn.Linear(64*8*8,384)\n","        self.fc2   = nn.Linear(384,192)\n","        self.fc3   = nn.Linear(192,100)\n","    def forward(self, x):\n","        x = self.pool1(F.relu(self.conv1(x)))\n","        x = self.pool2(F.relu(self.conv2(x)))\n","        x = torch.flatten(x,1)\n","        x = F.relu(self.fc1(x)); x = F.relu(self.fc2(x))\n","        return self.fc3(x)"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1746029723991,"user":{"displayName":"Mattia Cappellino","userId":"05271634366428679167"},"user_tz":-120},"id":"Nl1OmYlUb-aL"},"outputs":[],"source":["def train_one_epoch(model, optimizer, criterion, loader):\n","    model.train(); total_loss=correct=0\n","    for imgs, lbls in loader:\n","        imgs, lbls = imgs.to(device), lbls.to(device)\n","        optimizer.zero_grad()\n","        out = model(imgs); loss = criterion(out, lbls)\n","        loss.backward(); optimizer.step()\n","        total_loss += loss.item()*imgs.size(0)\n","        correct += out.argmax(1).eq(lbls).sum().item()\n","    return total_loss/len(loader.dataset), correct/len(loader.dataset)\n","\n","def eval_model(model, criterion, loader):\n","    model.eval(); total_loss=correct=0\n","    with torch.no_grad():\n","        for imgs, lbls in loader:\n","            imgs, lbls = imgs.to(device), lbls.to(device)\n","            out = model(imgs); loss = criterion(out, lbls)\n","            total_loss += loss.item()*imgs.size(0)\n","            correct += out.argmax(1).eq(lbls).sum().item()\n","    return total_loss/len(loader.dataset), correct/len(loader.dataset)"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1746029726040,"user":{"displayName":"Mattia Cappellino","userId":"05271634366428679167"},"user_tz":-120},"id":"gUZ-UxQRb-bC"},"outputs":[],"source":["# ── Optuna Objective Function\n","def objective(trial):\n","    # Suggest hyperparameters :contentReference[oaicite:11]{index=11}\n","    lr = trial.suggest_float(\"lr\", 1e-3, 1e-1, log=True)\n","    wd = trial.suggest_float(\"weight_decay\", 1e-5, 1e-3, log=True)\n","    bs = trial.suggest_categorical(\"batch_size\", [32, 64, 128])\n","    epochs = trial.suggest_int(\"epochs\", 50, 150, step=25)\n","\n","    # DataLoaders with variable batch size\n","    train_loader = DataLoader(train_dataset, batch_size=bs, shuffle=True, num_workers=2)\n","    val_loader   = DataLoader(val_dataset,   batch_size=bs, shuffle=False, num_workers=2)\n","\n","    # Model, optimizer, scheduler per trial\n","    model = LELeNetCIFAR().to(device)\n","    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=wd)\n","    scheduler = CosineAnnealingLR(optimizer, T_max=epochs)\n","    criterion = nn.CrossEntropyLoss()\n","\n","    best_val_acc = 0\n","    for epoch in range(1, epochs+1):\n","        train_one_epoch(model, optimizer, criterion, train_loader)\n","        val_loss, val_acc = eval_model(model, criterion, val_loader)\n","        scheduler.step()\n","        trial.report(val_acc, epoch)\n","        if trial.should_prune():\n","            raise optuna.TrialPruned()\n","        if val_acc \u003e best_val_acc:\n","            best_val_acc = val_acc\n","\n","    return best_val_acc"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"_UEJSInlczlL"},"outputs":[{"name":"stderr","output_type":"stream","text":["[I 2025-04-30 16:15:27,593] A new study created in memory with name: no-name-c9f5da54-f384-4be2-8399-781e7f1bfbcf\n"]}],"source":["# ── Run the Optuna Study\n","study = optuna.create_study(direction=\"maximize\")               # maximize validation accuracy :contentReference[oaicite:12]{index=12}\n","study.optimize(objective, n_trials=20)                          # e.g., 20 trials :contentReference[oaicite:13]{index=13}\n","print(\"Best hyperparameters:\", study.best_params)               # use these for final training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZjIHJT0JczmG"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W6dDdi5tczm9"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNGgY/0RMjyoUZRflsHxPN9","gpuType":"T4","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}