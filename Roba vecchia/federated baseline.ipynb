{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"NKqGuQno6f9b"},"outputs":[],"source":["#this is a template to adapt to my usecase\n","#old and useless"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FHm8KO_iMc21"},"outputs":[],"source":["\n","import os\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.optim.lr_scheduler import CosineAnnealingLR\n","from torch.utils.data import DataLoader, random_split\n","from torch.utils.tensorboard import SummaryWriter\n","import torchvision\n","import torchvision.transforms as T\n","import matplotlib.pyplot as plt\n","import random\n","import numpy as np\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LNj-TzkzMc5Q"},"outputs":[],"source":["\n","# ── 1. Reproducibility ───────────────────────────────────────────────────────────\n","seed = 42\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed_all(seed)\n","np.random.seed(seed)\n","random.seed(seed)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":43,"status":"ok","timestamp":1746000846845,"user":{"displayName":"Mattia Cappellino","userId":"05271634366428679167"},"user_tz":-120},"id":"tBoYFEF4M3uV","outputId":"7263bcc0-2e00-4892-d8a4-982f85a9e5fe"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cpu\n"]}],"source":["# ── 2. Device ───────────────────────────────────────────────────────────────────\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Using device:\", device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lPw9YJ0sM3ws"},"outputs":[],"source":["# ── 3. Data Preparation ─────────────────────────────────────────────────────────\n","# Transforms\n","transform_train = T.Compose([\n","    T.RandomCrop(32, padding=4),\n","    T.RandomHorizontalFlip(),\n","    T.ToTensor(),\n","    T.Normalize((0.5071, 0.4867, 0.4408),\n","                (0.2675, 0.2565, 0.2761)),\n","])\n","transform_test = T.Compose([\n","    T.ToTensor(),\n","    T.Normalize((0.5071, 0.4867, 0.4408),\n","                (0.2675, 0.2565, 0.2761)),\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9213,"status":"ok","timestamp":1746000035581,"user":{"displayName":"Mattia Cappellino","userId":"05271634366428679167"},"user_tz":-120},"id":"oSROpgGhM3y9","outputId":"f0a4b449-2aca-481c-e7c6-35dbcce9ba87"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 169M/169M [00:04<00:00, 40.6MB/s]\n"]}],"source":["# Download & split\n","dataset_full = torchvision.datasets.CIFAR100(\n","    root='./data', train=True, download=True, transform=transform_train)\n","val_size = 5000\n","train_size = len(dataset_full) - val_size\n","train_dataset, val_dataset = random_split(\n","    dataset_full, [train_size, val_size],\n","    generator=torch.Generator().manual_seed(seed))\n","test_dataset = torchvision.datasets.CIFAR100(\n","    root='./data', train=False, download=True, transform=transform_test)"]},{"cell_type":"markdown","source":[],"metadata":{"id":"2dbOqPaLba43"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"TjvRFt7iM31S"},"outputs":[],"source":["# DataLoaders (batch_size=64 per paper)\n","batch_size = 64\n","train_loader = DataLoader(\n","    train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n","val_loader = DataLoader(\n","    val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n","test_loader = DataLoader(\n","    test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CewOwdsQM33K"},"outputs":[],"source":["# ── 4. Model Definition ─────────────────────────────────────────────────────────\n","class LELeNetCIFAR(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.conv1 = nn.Conv2d(3, 64, kernel_size=5, padding=2)\n","        self.pool1 = nn.MaxPool2d(2)\n","        self.conv2 = nn.Conv2d(64, 64, kernel_size=5, padding=2)\n","        self.pool2 = nn.MaxPool2d(2)\n","        self.fc1   = nn.Linear(64 * 8 * 8, 384)\n","        self.fc2   = nn.Linear(384, 192)\n","        self.fc3   = nn.Linear(192, 100)\n","\n","    def forward(self, x):\n","        x = self.pool1(F.relu(self.conv1(x)))\n","        x = self.pool2(F.relu(self.conv2(x)))\n","        x = torch.flatten(x, 1)\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        return self.fc3(x)\n","\n","model = LELeNetCIFAR().to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rvJAHXx0M_Qx"},"outputs":[],"source":["# ── 5. Optimizer, Scheduler, Loss ────────────────────────────────────────────────\n","optimizer = optim.SGD(\n","    model.parameters(),\n","    lr=0.01,           # per paper\n","    momentum=0.9,      # per paper\n","    weight_decay=4e-4  # per paper\n",")\n","num_epochs = 100\n","scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs)\n","criterion = nn.CrossEntropyLoss()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f5kC0CIjM_TC"},"outputs":[],"source":["# ── 6. Logging & Checkpointing Setup ────────────────────────────────────────────\n","writer = SummaryWriter(log_dir='./logs')\n","ckpt_dir = './checkpoints'\n","os.makedirs(ckpt_dir, exist_ok=True)\n","\n","def save_checkpoint(epoch, best=False):\n","    path = os.path.join(\n","        ckpt_dir,\n","        f'{\"best\" if best else \"last\"}_ckpt_epoch_{epoch}.pth')\n","    torch.save({\n","        'epoch': epoch,\n","        'model_state': model.state_dict(),\n","        'optim_state': optimizer.state_dict(),\n","        'sched_state': scheduler.state_dict(),\n","        'rng_state': torch.get_rng_state(),\n","    }, path)\n","\n","def load_checkpoint(path):\n","    ckpt = torch.load(path)\n","    model.load_state_dict(ckpt['model_state'])\n","    optimizer.load_state_dict(ckpt['optim_state'])\n","    scheduler.load_state_dict(ckpt['sched_state'])\n","    torch.set_rng_state(ckpt['rng_state'])\n","    return ckpt['epoch']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xIf4kPDiM_VE"},"outputs":[],"source":["# ── 7. Training & Evaluation Functions ─────────────────────────────────────────\n","def train_one_epoch():\n","    model.train()\n","    running_loss = correct = total = 0\n","    for images, labels in train_loader:\n","        images, labels = images.to(device), labels.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        running_loss += loss.item() * images.size(0)\n","        preds = outputs.argmax(dim=1)\n","        correct += preds.eq(labels).sum().item()\n","        total += labels.size(0)\n","    return running_loss / total, correct / total\n","\n","def eval_model(loader):\n","    model.eval()\n","    running_loss = correct = total = 0\n","    with torch.no_grad():\n","        for images, labels in loader:\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","            running_loss += loss.item() * images.size(0)\n","            preds = outputs.argmax(dim=1)\n","            correct += preds.eq(labels).sum().item()\n","            total += labels.size(0)\n","    return running_loss / total, correct / total"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xmTgXyRwM_W3","executionInfo":{"status":"ok","timestamp":1746021744393,"user_tz":-120,"elapsed":20887740,"user":{"displayName":"Mattia Cappellino","userId":"05271634366428679167"}},"outputId":"3824ee06-d3d6-4448-e901-b0f438eef931"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100  Train: loss=4.1107, acc=0.0678  Val:   loss=3.7990, acc=0.1128\n","Epoch 2/100  Train: loss=3.5657, acc=0.1488  Val:   loss=3.3450, acc=0.1922\n","Epoch 3/100  Train: loss=3.2182, acc=0.2091  Val:   loss=3.1327, acc=0.2260\n","Epoch 4/100  Train: loss=2.9821, acc=0.2538  Val:   loss=2.8528, acc=0.2862\n","Epoch 5/100  Train: loss=2.7878, acc=0.2925  Val:   loss=2.7273, acc=0.2984\n","Epoch 6/100  Train: loss=2.6293, acc=0.3254  Val:   loss=2.6252, acc=0.3314\n","Epoch 7/100  Train: loss=2.5032, acc=0.3521  Val:   loss=2.6146, acc=0.3478\n","Epoch 8/100  Train: loss=2.4114, acc=0.3720  Val:   loss=2.4780, acc=0.3586\n","Epoch 9/100  Train: loss=2.3255, acc=0.3911  Val:   loss=2.5215, acc=0.3570\n","Epoch 10/100  Train: loss=2.2452, acc=0.4074  Val:   loss=2.4799, acc=0.3674\n","Epoch 11/100  Train: loss=2.1773, acc=0.4223  Val:   loss=2.3929, acc=0.3794\n","Epoch 12/100  Train: loss=2.1189, acc=0.4340  Val:   loss=2.3660, acc=0.3910\n","Epoch 13/100  Train: loss=2.0663, acc=0.4450  Val:   loss=2.3330, acc=0.4008\n","Epoch 14/100  Train: loss=2.0209, acc=0.4574  Val:   loss=2.2916, acc=0.4094\n","Epoch 15/100  Train: loss=1.9734, acc=0.4668  Val:   loss=2.2565, acc=0.4216\n","Epoch 16/100  Train: loss=1.9302, acc=0.4772  Val:   loss=2.3273, acc=0.4078\n","Epoch 17/100  Train: loss=1.8828, acc=0.4890  Val:   loss=2.2511, acc=0.4188\n","Epoch 18/100  Train: loss=1.8446, acc=0.4973  Val:   loss=2.2244, acc=0.4374\n","Epoch 19/100  Train: loss=1.8195, acc=0.5036  Val:   loss=2.2206, acc=0.4294\n","Epoch 20/100  Train: loss=1.7694, acc=0.5122  Val:   loss=2.2225, acc=0.4310\n","Epoch 21/100  Train: loss=1.7424, acc=0.5203  Val:   loss=2.2181, acc=0.4312\n","Epoch 22/100  Train: loss=1.7034, acc=0.5299  Val:   loss=2.2683, acc=0.4360\n","Epoch 23/100  Train: loss=1.6807, acc=0.5335  Val:   loss=2.2262, acc=0.4416\n","Epoch 24/100  Train: loss=1.6622, acc=0.5408  Val:   loss=2.1971, acc=0.4394\n","Epoch 25/100  Train: loss=1.6297, acc=0.5475  Val:   loss=2.2471, acc=0.4346\n","Epoch 26/100  Train: loss=1.6090, acc=0.5535  Val:   loss=2.1905, acc=0.4508\n","Epoch 27/100  Train: loss=1.5707, acc=0.5590  Val:   loss=2.2370, acc=0.4480\n","Epoch 28/100  Train: loss=1.5529, acc=0.5656  Val:   loss=2.2314, acc=0.4422\n","Epoch 29/100  Train: loss=1.5318, acc=0.5714  Val:   loss=2.1742, acc=0.4586\n","Epoch 30/100  Train: loss=1.4929, acc=0.5785  Val:   loss=2.1015, acc=0.4682\n","Epoch 31/100  Train: loss=1.4542, acc=0.5886  Val:   loss=2.1558, acc=0.4694\n","Epoch 32/100  Train: loss=1.4387, acc=0.5941  Val:   loss=2.2255, acc=0.4570\n","Epoch 33/100  Train: loss=1.4088, acc=0.5993  Val:   loss=2.2755, acc=0.4560\n","Epoch 34/100  Train: loss=1.3885, acc=0.6042  Val:   loss=2.2838, acc=0.4490\n","Epoch 35/100  Train: loss=1.3662, acc=0.6103  Val:   loss=2.1577, acc=0.4556\n","Epoch 36/100  Train: loss=1.3421, acc=0.6146  Val:   loss=2.1705, acc=0.4670\n","Epoch 37/100  Train: loss=1.3155, acc=0.6235  Val:   loss=2.1953, acc=0.4626\n","Epoch 38/100  Train: loss=1.3060, acc=0.6248  Val:   loss=2.1677, acc=0.4744\n","Epoch 39/100  Train: loss=1.2756, acc=0.6313  Val:   loss=2.2219, acc=0.4556\n","Epoch 40/100  Train: loss=1.2532, acc=0.6361  Val:   loss=2.1705, acc=0.4672\n","Epoch 41/100  Train: loss=1.2371, acc=0.6420  Val:   loss=2.1843, acc=0.4782\n","Epoch 42/100  Train: loss=1.1943, acc=0.6538  Val:   loss=2.1698, acc=0.4722\n","Epoch 43/100  Train: loss=1.1769, acc=0.6565  Val:   loss=2.2110, acc=0.4720\n","Epoch 44/100  Train: loss=1.1637, acc=0.6595  Val:   loss=2.1375, acc=0.4808\n","Epoch 45/100  Train: loss=1.1413, acc=0.6659  Val:   loss=2.1813, acc=0.4790\n","Epoch 46/100  Train: loss=1.1172, acc=0.6705  Val:   loss=2.2094, acc=0.4656\n","Epoch 47/100  Train: loss=1.0826, acc=0.6820  Val:   loss=2.2235, acc=0.4730\n","Epoch 48/100  Train: loss=1.0686, acc=0.6858  Val:   loss=2.1732, acc=0.4856\n","Epoch 49/100  Train: loss=1.0336, acc=0.6933  Val:   loss=2.2726, acc=0.4736\n","Epoch 50/100  Train: loss=1.0184, acc=0.7014  Val:   loss=2.1729, acc=0.4776\n","Epoch 51/100  Train: loss=0.9950, acc=0.7068  Val:   loss=2.1828, acc=0.4876\n","Epoch 52/100  Train: loss=0.9769, acc=0.7098  Val:   loss=2.2080, acc=0.4864\n","Epoch 53/100  Train: loss=0.9351, acc=0.7182  Val:   loss=2.1808, acc=0.4994\n","Epoch 54/100  Train: loss=0.9157, acc=0.7247  Val:   loss=2.2307, acc=0.5018\n","Epoch 55/100  Train: loss=0.8999, acc=0.7317  Val:   loss=2.2278, acc=0.4954\n","Epoch 56/100  Train: loss=0.8741, acc=0.7356  Val:   loss=2.2886, acc=0.4880\n","Epoch 57/100  Train: loss=0.8523, acc=0.7447  Val:   loss=2.2774, acc=0.4918\n","Epoch 58/100  Train: loss=0.8352, acc=0.7484  Val:   loss=2.2613, acc=0.4884\n","Epoch 59/100  Train: loss=0.8126, acc=0.7549  Val:   loss=2.2474, acc=0.4956\n","Epoch 60/100  Train: loss=0.7962, acc=0.7580  Val:   loss=2.2760, acc=0.4940\n","Epoch 61/100  Train: loss=0.7656, acc=0.7663  Val:   loss=2.2207, acc=0.5160\n","Epoch 62/100  Train: loss=0.7384, acc=0.7761  Val:   loss=2.2628, acc=0.5084\n","Epoch 63/100  Train: loss=0.7146, acc=0.7800  Val:   loss=2.2950, acc=0.5018\n","Epoch 64/100  Train: loss=0.7041, acc=0.7858  Val:   loss=2.3141, acc=0.5060\n","Epoch 65/100  Train: loss=0.6779, acc=0.7933  Val:   loss=2.2626, acc=0.5116\n","Epoch 66/100  Train: loss=0.6591, acc=0.7994  Val:   loss=2.3040, acc=0.5080\n","Epoch 67/100  Train: loss=0.6297, acc=0.8072  Val:   loss=2.3120, acc=0.5088\n","Epoch 68/100  Train: loss=0.6154, acc=0.8101  Val:   loss=2.3383, acc=0.5078\n","Epoch 69/100  Train: loss=0.5955, acc=0.8177  Val:   loss=2.3629, acc=0.5038\n","Epoch 70/100  Train: loss=0.5806, acc=0.8204  Val:   loss=2.3465, acc=0.5012\n","Epoch 71/100  Train: loss=0.5587, acc=0.8289  Val:   loss=2.4362, acc=0.5046\n","Epoch 72/100  Train: loss=0.5394, acc=0.8340  Val:   loss=2.3959, acc=0.5126\n","Epoch 73/100  Train: loss=0.5287, acc=0.8367  Val:   loss=2.3543, acc=0.5122\n","Epoch 74/100  Train: loss=0.5103, acc=0.8426  Val:   loss=2.3982, acc=0.5088\n","Epoch 75/100  Train: loss=0.4951, acc=0.8482  Val:   loss=2.3566, acc=0.5150\n","Epoch 76/100  Train: loss=0.4763, acc=0.8544  Val:   loss=2.4420, acc=0.5152\n","Epoch 77/100  Train: loss=0.4618, acc=0.8582  Val:   loss=2.4229, acc=0.5166\n","Epoch 78/100  Train: loss=0.4434, acc=0.8643  Val:   loss=2.4134, acc=0.5190\n","Epoch 79/100  Train: loss=0.4322, acc=0.8670  Val:   loss=2.4432, acc=0.5196\n","Epoch 80/100  Train: loss=0.4179, acc=0.8719  Val:   loss=2.4583, acc=0.5220\n","Epoch 81/100  Train: loss=0.4099, acc=0.8733  Val:   loss=2.4486, acc=0.5132\n","Epoch 82/100  Train: loss=0.3931, acc=0.8798  Val:   loss=2.4681, acc=0.5186\n","Epoch 83/100  Train: loss=0.3898, acc=0.8826  Val:   loss=2.4742, acc=0.5238\n","Epoch 84/100  Train: loss=0.3687, acc=0.8873  Val:   loss=2.5458, acc=0.5084\n","Epoch 85/100  Train: loss=0.3655, acc=0.8877  Val:   loss=2.5093, acc=0.5158\n","Epoch 86/100  Train: loss=0.3549, acc=0.8923  Val:   loss=2.4911, acc=0.5230\n","Epoch 87/100  Train: loss=0.3483, acc=0.8950  Val:   loss=2.4971, acc=0.5258\n","Epoch 88/100  Train: loss=0.3427, acc=0.8992  Val:   loss=2.5386, acc=0.5142\n","Epoch 89/100  Train: loss=0.3341, acc=0.9003  Val:   loss=2.5360, acc=0.5210\n","Epoch 90/100  Train: loss=0.3264, acc=0.9020  Val:   loss=2.5045, acc=0.5272\n","Epoch 91/100  Train: loss=0.3300, acc=0.9010  Val:   loss=2.5476, acc=0.5230\n","Epoch 92/100  Train: loss=0.3192, acc=0.9047  Val:   loss=2.5470, acc=0.5266\n","Epoch 93/100  Train: loss=0.3186, acc=0.9038  Val:   loss=2.5429, acc=0.5238\n","Epoch 94/100  Train: loss=0.3187, acc=0.9046  Val:   loss=2.5265, acc=0.5250\n","Epoch 95/100  Train: loss=0.3135, acc=0.9057  Val:   loss=2.5314, acc=0.5286\n","Epoch 96/100  Train: loss=0.3078, acc=0.9087  Val:   loss=2.5421, acc=0.5216\n","Epoch 97/100  Train: loss=0.3114, acc=0.9064  Val:   loss=2.5421, acc=0.5216\n","Epoch 98/100  Train: loss=0.3026, acc=0.9106  Val:   loss=2.5797, acc=0.5234\n","Epoch 99/100  Train: loss=0.3066, acc=0.9092  Val:   loss=2.5471, acc=0.5260\n","Epoch 100/100  Train: loss=0.3051, acc=0.9079  Val:   loss=2.4963, acc=0.5264\n"]}],"source":["# ── 8. Main Training Loop ───────────────────────────────────────────────────────\n","best_val_acc = 0.0\n","history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n","\n","for epoch in range(1, num_epochs + 1):\n","    train_loss, train_acc = train_one_epoch()\n","    val_loss, val_acc = eval_model(val_loader)\n","\n","    scheduler.step()\n","    history['train_loss'].append(train_loss)\n","    history['train_acc'].append(train_acc)\n","    history['val_loss'].append(val_loss)\n","    history['val_acc'].append(val_acc)\n","\n","    print(f\"Epoch {epoch}/{num_epochs}  \"\n","          f\"Train: loss={train_loss:.4f}, acc={train_acc:.4f}  \"\n","          f\"Val:   loss={val_loss:.4f}, acc={val_acc:.4f}\")\n","\n","    writer.add_scalars('Loss', {'train': train_loss, 'val': val_loss}, epoch)\n","    writer.add_scalars('Acc',  {'train': train_acc,  'val': val_acc},   epoch)\n","\n","    # Checkpoint\n","    save_checkpoint(epoch, best=False)\n","    if val_acc > best_val_acc:\n","        best_val_acc = val_acc\n","        save_checkpoint(epoch, best=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":193},"executionInfo":{"elapsed":154,"status":"error","timestamp":1746025770994,"user":{"displayName":"Mattia Cappellino","userId":"05271634366428679167"},"user_tz":-120},"id":"uqqQJKh8NFuv","outputId":"a804e448-1f1b-4fde-f5b4-164d317dbb70"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'eval_model' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-a08fdc8dea4e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# ── 9. Final Test Evaluation ───────────────────────────────────────────────────\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nTest: loss={test_loss:.4f}, acc={test_acc:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'eval_model' is not defined"]}],"source":["# ── 9. Final Test Evaluation ───────────────────────────────────────────────────\n","test_loss, test_acc = eval_model(test_loader)\n","print(f\"\\nTest: loss={test_loss:.4f}, acc={test_acc:.4f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9EH9OGq7NFxR"},"outputs":[],"source":["# ── 10. Plot Accuracies ─────────────────────────────────────────────────────────\n","plt.plot(history['train_acc'], label='Train Acc')\n","plt.plot(history['val_acc'],   label='Val Acc')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RdWoj2RbNFzF"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"authorship_tag":"ABX9TyOOxP1ork1xDfJvztKBQ6Ua"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}